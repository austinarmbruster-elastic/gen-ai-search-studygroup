{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Google Vertex With LangChain\n",
    "\n",
    "First follow the instructions in the notebook for GoogleVertex_Basics to ensure your keys are set up to authenticate into the Google service\n",
    "\n",
    "Documentation - https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's work with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Rishi Sunak'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "llm = VertexAI()\n",
    "\n",
    "## Let's do a simple completion\n",
    "llm.predict(\"The Prime Minister of the United Kingdom is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Who.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You could do a more complex completion and it would handle it with no issues\n",
    "chat= \"\"\"\n",
    "Lou Costello: All I’m trying to find out is what’s the guy’s name on first base.\n",
    "\n",
    "Bud Abbott: No. What is on second base.\n",
    "\n",
    "Lou Costello: I’m not asking you who’s on second.\n",
    "\n",
    "Bud Abbott: Who’s on first.\n",
    "\n",
    "Lou Costello: One base at a time!\n",
    "\n",
    "Bud Abbott: Well, don’t change the players around.\n",
    "\n",
    "Lou Costello: I’m not changing nobody!\n",
    "\n",
    "Bud Abbott: Take it easy, buddy.\n",
    "\n",
    "Lou Costello: I’m only asking you, who’s the guy on first base?\n",
    "\n",
    "Bud Abbott: That’s right.\n",
    "\n",
    "Lou Costello: Ok.\n",
    "\n",
    "Bud Abbott: All right.\n",
    "\n",
    "Lou Costello: What’s the guy’s name on first base?\n",
    "\n",
    "Bud Abbott:\n",
    "\"\"\"\n",
    "\n",
    "### The large language model is not always funny\n",
    "llm.predict(chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat bot With memory in LangChain with Google Vertex\n",
    "\n",
    "# from langchain import ConversationChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "import json\n",
    "# pretty printing JSON objects\n",
    "def json_pretty(input_object):\n",
    "  print(json.dumps(input_object, indent=4))\n",
    "\n",
    "\n",
    "import textwrap\n",
    "# wrap text when printing, because colab scrolls output to the right too much\n",
    "def wrap_text(text, width):\n",
    "    wrapped_text = textwrap.wrap(text, width)\n",
    "    return '\\n'.join(wrapped_text)\n",
    "\n",
    "template = \"\"\"The following is a serious conversation between a human and a TV\n",
    "News Anchor named Newsy McNewserson.\n",
    "The Anchor provides autoritative information and commentary in short responses.\n",
    "If the Anchor does not know the answer to a question,\n",
    "it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "Anchor:\"\"\"\n",
    "\n",
    "MEMORY = ConversationBufferWindowMemory(ai_prefix=\"Anchor\", k=2)\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = LLMChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=MEMORY,\n",
    ")\n",
    "\n",
    "def chatLoop():\n",
    "  print(\" -- Have a conversation with a TV news Anchor: \")\n",
    "  print(\" -- Ask this AI \\\"what is in the news?\\\" \")\n",
    "  print(\" -- type 'exit' when done\")\n",
    "\n",
    "  user_input = input(\"> \")\n",
    "  while not user_input.lower().startswith(\"exit\"):\n",
    "      print( conversation.run(user_input) )\n",
    "      print(\" -- type 'exit' when done\")\n",
    "      user_input = input(\"> \")\n",
    "  print(\"\\n -- end conversation --\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Have a conversation with a TV news Anchor: \n",
      " -- Ask this AI \"what is in the news?\" \n",
      " -- type 'exit' when done\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a serious conversation between a human and a TV\n",
      "News Anchor named Newsy McNewserson.\n",
      "The Anchor provides autoritative information and commentary in short responses.\n",
      "If the Anchor does not know the answer to a question,\n",
      "it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hello\n",
      "Anchor:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hello.  How may I help you?\n",
      " -- type 'exit' when done\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a serious conversation between a human and a TV\n",
      "News Anchor named Newsy McNewserson.\n",
      "The Anchor provides autoritative information and commentary in short responses.\n",
      "If the Anchor does not know the answer to a question,\n",
      "it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hello\n",
      "Anchor:  Hello.  How may I help you?\n",
      "Human: What is in the news today?\n",
      "Anchor:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Here are some of the top headlines for today:\n",
      "\n",
      "* Russia-Ukraine Crisis: Russia has announced a partial withdrawal of troops from the Ukrainian border, but the United States and its allies remain skeptical, saying that they have not seen any significant reduction in Russian military presence.\n",
      "* COVID-19 Pandemic: The World Health Organization (WHO) has warned that the COVID-19 pandemic is not over yet, and that new variants could emerge. The WHO has urged countries to continue to take measures to prevent the spread of the virus, such as vaccination and mask-wearing.\n",
      "* US Inflation: The US inflation rate hit a \n",
      " -- type 'exit' when done\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a serious conversation between a human and a TV\n",
      "News Anchor named Newsy McNewserson.\n",
      "The Anchor provides autoritative information and commentary in short responses.\n",
      "If the Anchor does not know the answer to a question,\n",
      "it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hello\n",
      "Anchor:  Hello.  How may I help you?\n",
      "Human: What is in the news today?\n",
      "Anchor:  Here are some of the top headlines for today:\n",
      "\n",
      "* Russia-Ukraine Crisis: Russia has announced a partial withdrawal of troops from the Ukrainian border, but the United States and its allies remain skeptical, saying that they have not seen any significant reduction in Russian military presence.\n",
      "* COVID-19 Pandemic: The World Health Organization (WHO) has warned that the COVID-19 pandemic is not over yet, and that new variants could emerge. The WHO has urged countries to continue to take measures to prevent the spread of the virus, such as vaccination and mask-wearing.\n",
      "* US Inflation: The US inflation rate hit a \n",
      "Human: what is today's date?\n",
      "Anchor:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Today is Thursday, February 24, 2023\n",
      "\n",
      " -- type 'exit' when done\n",
      "\n",
      " -- end conversation --\n"
     ]
    }
   ],
   "source": [
    "## start a new chat each time\n",
    "MEMORY.clear()\n",
    "## start the chat\n",
    "chatLoop()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
