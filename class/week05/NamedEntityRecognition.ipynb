{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Want to learn in way more detail what this is all about\n",
    "[https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a](https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install -q python_dotenv\n",
    "! pip install -q torch torchvision torchaudio\n",
    "! pip install -q seqeval\n",
    "! pip install -q transformers\n",
    "! pip install -q eland sentence_transformers requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESTART YOUR ENVIRONMENT.  \n",
    "\n",
    "This may be as simple as closing and relaunching visual studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id= \"distilbert-base-cased-finetuned-conll03-english\"\n",
    "es_model_id = f\"elastic__{model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://elastic:3OE7b4jFjwr9KjHZFCs0pc4P@esre-demo.es.us-central1.gcp.cloud.es.io:443\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "\n",
    "\n",
    "domain=os.environ[\"ELASTIC_DOMAIN\"]\n",
    "port=os.environ[\"ELASTIC_PORT\"]\n",
    "protocol=os.environ[\"ELASTIC_PROTOCOL\"]\n",
    "user=os.environ[\"ELASTIC_USER\"]\n",
    "password=os.environ[\"ELASTIC_PASSWORD\"]\n",
    "\n",
    "es_url = f\"{protocol}://{user}:{password}@{domain}:{port}\"\n",
    "print(es_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/dev/gen-ai-search-studygroup/env/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
      "/var/folders/k9/1gwggc7n2yg1zq_gsfsfsb3w0000gn/T/ipykernel_19374/466817261.py:19: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  es = elasticsearch.Elasticsearch(es_url, timeout=300)  # 5 minute timeout\n",
      "100%|██████████| 63/63 [01:18<00:00,  1.25s/ parts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deploying model:  {\"error\":{\"root_cause\":[{\"type\":\"status_exception\",\"reason\":\"Could not start deployment because no ML nodes with sufficient capacity were found\"}],\"type\":\"status_exception\",\"reason\":\"Could not start deployment because no ML nodes with sufficient capacity were found\",\"caused_by\":{\"type\":\"illegal_state_exception\",\"reason\":\"Could not start deployment because no suitable nodes were found, allocation explanation [Could not assign (more) allocations on node [zMpKf6r_QxWR-Sd-AB8phQ]. Reason: This node has insufficient allocated processors. Available processors [16], free processors [0], processors required for each allocation of this model [1]]\"}},\"status\":429}\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "import requests\n",
    "\n",
    "# Load a Hugging Face transformers model directly from the model hub\n",
    "tm = TransformerModel(f\"elastic/{model_id}\", \"ner\")\n",
    "\n",
    "\n",
    "# Export the model in a TorchScrpt representation which Elasticsearch uses\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "e = None\n",
    "\n",
    "# Import model into Elasticsearch\n",
    "es = elasticsearch.Elasticsearch(es_url, timeout=300)  # 5 minute timeout\n",
    "ptm = PyTorchModel(es, tm.elasticsearch_model_id())\n",
    "try:\n",
    "  ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "except Exception as error:\n",
    "  # Handle the BadRequestError exception here\n",
    "  if error.meta.status == 400 and error.message == \"resource_already_exists_exception\":\n",
    "    print(\"Done -- the model was already loaded\")\n",
    "  else:\n",
    "    print(\"An error occurred:\", str(error))\n",
    "\n",
    "\n",
    "def deploy_model(model_id,es_url):\n",
    "  url = f\"{es_url}/_ml/trained_models/{model_id}/deployment/_start\"\n",
    "  response = requests.post(url)\n",
    "  if response.status_code == 200:\n",
    "    print(\"Model Deployed\")\n",
    "  else:\n",
    "    print(\"Error deploying model: \", response.text)\n",
    "\n",
    "deploy_model(es_model_id,es_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to deploy the model\n",
    "\n",
    "* If you are running in Elastic Cloud, make sure you have at least 1 ML node configured\n",
    "* In Kibana go to Stack Management > Machine Learning \n",
    "* Synchronize the saved objects\n",
    "\n",
    "![deploy](img/sync.jpg)\n",
    "\n",
    "* Refresh the page and go to the Trained Model Tab.\n",
    "* Start the model, default settings will be fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON posted successfully to your URL\n",
      "{\n",
      "    \"predicted_value\": \"\\nMy name is [Jonas](PER&Jonas)\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "    \"entities\": [\n",
      "        {\n",
      "            \"entity\": \"Jonas\",\n",
      "            \"class_name\": \"PER\",\n",
      "            \"class_probability\": 0.9988214100479974,\n",
      "            \"start_pos\": 12,\n",
      "            \"end_pos\": 17\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "lyrics = \"\"\"\n",
    "My name is Jonas\n",
    "I'm carryin' the wheel\n",
    "Thanks for all you've shown us\n",
    "But this is how we feel \"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def use_hosted_ml_post(json_payload, url):\n",
    "  json_string = json.dumps(json_payload)\n",
    "  headers = {'Content-Type': 'application/json'}\n",
    "  response = requests.post(es_url+url, data=json_string, headers=headers)\n",
    "  if response.status_code == 200:\n",
    "    print(\"JSON posted successfully to your URL\")\n",
    "    result = response.json()\n",
    "    print(json.dumps(result, indent=4))\n",
    "  else:\n",
    "    print(\"Error posting JSON:\", response.text)\n",
    "\n",
    "payload = {\n",
    "  \"docs\": [\n",
    "    {\n",
    "      \"text_field\": lyrics\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "url = f\"/_ml/trained_models/{es_model_id}/deployment/_infer\"\n",
    "use_hosted_ml_post(payload,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/1gwggc7n2yg1zq_gsfsfsb3w0000gn/T/ipykernel_19374/2406413618.py:14: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.ingest.put_pipeline(id='week5_ner', body=body)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference = {\n",
    "       \"inference\": {\n",
    "         \"model_id\": es_model_id,\n",
    "         \"field_map\": {\n",
    "           \"message\": \"text_field\"\n",
    "         }\n",
    "       }\n",
    "    }\n",
    "\n",
    "body = {\n",
    "   \"processors\": [inference]\n",
    "}\n",
    "\n",
    "es.ingest.put_pipeline(id='week5_ner', body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"docs\": [\n",
      "        {\n",
      "            \"doc\": {\n",
      "                \"_index\": \"_index\",\n",
      "                \"_id\": \"_id\",\n",
      "                \"_version\": \"-3\",\n",
      "                \"_source\": {\n",
      "                    \"message\": \"\\nMy name is Jonas\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                    \"ml\": {\n",
      "                        \"inference\": {\n",
      "                            \"predicted_value\": \"\\nMy name is [Jonas](PER&Jonas)\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                            \"entities\": [\n",
      "                                {\n",
      "                                    \"entity\": \"Jonas\",\n",
      "                                    \"class_name\": \"PER\",\n",
      "                                    \"class_probability\": 0.9988214100479974,\n",
      "                                    \"start_pos\": 12,\n",
      "                                    \"end_pos\": 17\n",
      "                                }\n",
      "                            ],\n",
      "                            \"model_id\": \"elastic__distilbert-base-cased-finetuned-conll03-english\"\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"_ingest\": {\n",
      "                    \"timestamp\": \"2023-09-28T01:23:49.261324091Z\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "  {\n",
    "      \"_source\": {\n",
    "          \"message\": lyrics\n",
    "      }\n",
    "  }\n",
    "]\n",
    "\n",
    "import json\n",
    "# pretty printing JSON objects\n",
    "def json_pretty(input_object):\n",
    "  print(json.dumps(input_object, indent=4))\n",
    "\n",
    "json_pretty(es.ingest.simulate(id='week5_ner', docs=docs).body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/1gwggc7n2yg1zq_gsfsfsb3w0000gn/T/ipykernel_19374/437864838.py:15: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.ingest.put_pipeline(id='week5_ner', body=body)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_extract = {\n",
    "       \"script\": {\n",
    "         \"lang\": \"painless\",\n",
    "         \"source\": \"\"\"\n",
    "String msg = ctx['message'];\n",
    "String predicted = ctx['ml']['inference']['predicted_value'];\n",
    "ctx['message_ner'] = ctx['ml']['inference']['predicted_value'];\n",
    "\"\"\"\n",
    "       }\n",
    "    }\n",
    "\n",
    "body = {\n",
    "   \"processors\": [inference, script_extract]\n",
    "}\n",
    "es.ingest.put_pipeline(id='week5_ner', body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"docs\": [\n",
      "        {\n",
      "            \"doc\": {\n",
      "                \"_index\": \"_index\",\n",
      "                \"_id\": \"_id\",\n",
      "                \"_version\": \"-3\",\n",
      "                \"_source\": {\n",
      "                    \"message\": \"\\nMy name is Jonas\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                    \"message_ner\": \"\\nMy name is [Jonas](PER&Jonas)\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                    \"ml\": {\n",
      "                        \"inference\": {\n",
      "                            \"predicted_value\": \"\\nMy name is [Jonas](PER&Jonas)\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                            \"entities\": [\n",
      "                                {\n",
      "                                    \"entity\": \"Jonas\",\n",
      "                                    \"class_name\": \"PER\",\n",
      "                                    \"class_probability\": 0.9988214100479974,\n",
      "                                    \"start_pos\": 12,\n",
      "                                    \"end_pos\": 17\n",
      "                                }\n",
      "                            ],\n",
      "                            \"model_id\": \"elastic__distilbert-base-cased-finetuned-conll03-english\"\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"_ingest\": {\n",
      "                    \"timestamp\": \"2023-09-28T01:30:12.673155135Z\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_pretty(es.ingest.simulate(id='week5_ner', docs=docs).body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/1gwggc7n2yg1zq_gsfsfsb3w0000gn/T/ipykernel_19374/4275707389.py:14: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.ingest.put_pipeline(id='week5_ner', body=body)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"docs\": [\n",
      "        {\n",
      "            \"doc\": {\n",
      "                \"_index\": \"_index\",\n",
      "                \"_id\": \"_id\",\n",
      "                \"_version\": \"-3\",\n",
      "                \"_source\": {\n",
      "                    \"message\": \"\\nMy name is Jonas\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \",\n",
      "                    \"message_ner\": \"\\nMy name is [Jonas](PER&Jonas)\\nI'm carryin' the wheel\\nThanks for all you've shown us\\nBut this is how we feel \"\n",
      "                },\n",
      "                \"_ingest\": {\n",
      "                    \"timestamp\": \"2023-09-28T01:31:24.086903766Z\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "remove = {\n",
    "       \"remove\": {\n",
    "         \"field\": [\n",
    "           \"ml\"\n",
    "         ],\n",
    "         \"ignore_missing\": True,\n",
    "         \"ignore_failure\": True\n",
    "       }\n",
    "    }\n",
    "\n",
    "body = {\n",
    "   \"processors\": [inference, script_extract,remove]\n",
    "}\n",
    "es.ingest.put_pipeline(id='week5_ner', body=body)\n",
    "json_pretty(es.ingest.simulate(id='week5_ner', docs=docs).body)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
