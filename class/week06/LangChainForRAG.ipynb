{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just enough LangChain for RAG\n",
    "\n",
    "I use OpenAI below. You may need to adjust for a different LLM using examples from week 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| es.info()['tagline']: 'You Know, for Search'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from icecream import ic\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = None\n",
    "\n",
    "if 'ELASTIC_CLOUD_ID' in os.environ:\n",
    "  es = Elasticsearch(\n",
    "    cloud_id=os.environ['ELASTIC_CLOUD_ID'],\n",
    "    basic_auth=(os.environ['ELASTIC_USER'], os.environ['ELASTIC_PASSWORD']),\n",
    "    request_timeout=30\n",
    "  )\n",
    "elif 'ELASTIC_URL' in os.environ:\n",
    "  es = Elasticsearch(\n",
    "    os.environ['ELASTIC_URL'],\n",
    "    basic_auth=(os.environ['ELASTIC_USER'], os.environ['ELASTIC_PASSWORD']),\n",
    "    request_timeout=30\n",
    "  )\n",
    "else:\n",
    "  print(\"env needs to set either ELASTIC_CLOUD_ID or ELASTIC_URL\")\n",
    "\n",
    "if es:\n",
    "    ic(es.info()['tagline']) # should return cluster info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a langchain abstraction for ELSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
    "\n",
    "index_name = \"elser_sotu_paragraphs\"\n",
    "\n",
    "es_elser = ElasticsearchStore(\n",
    "    es_connection=es,\n",
    "    index_name=index_name,\n",
    "    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a simple semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| es_elser.similarity_search(human_input, k=1)[0]: Document(page_content='shake the very foundations of the free world, thinking he could make it bend to his menacing ways. But he badly miscalculated. He thought he could roll into Ukraine and the world would roll over. Instead, he met with a wall of strength he never anticipated or imagined. He met the Ukrainian people.From President Zelenskiy, their—to every Ukrainian, their fearlessness, their courage, their determination literally inspires the world. Groups of citizens blocking tanks with their bodies.Everyone from students to retirees, to teachers turned soldiers defending their homeland. And in this struggle—President Zelenskiy said in his speech to the European Parliament, \"Light will win over darkness.\"The Ukrainian Ambassador to the United States is here tonight sitting with the First Lady. Let each of', metadata={'date': 'March 1, 2022', 'sotu_id': 'Biden-2022-03-01', 'date_iso': '2022-03-01', 'administration': 'Biden', 'chunk': 1, 'url': 'https://www.govinfo.gov/content/pkg/DCPD-202200127/html/DCPD-202200127.htm'})\n"
     ]
    }
   ],
   "source": [
    "human_input = \"what did Biden say about the Ukrainian people?\"\n",
    "\n",
    "best_result = ic(es_elser.similarity_search(human_input, k=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the LLM ready\n",
    "\n",
    "This is likely the part you'll have to change if you are not using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "def load_openai_llm():\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    default_model = \"gpt-3.5-turbo\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.3,\n",
    "        model=default_model\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "LLM=load_openai_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boris Johnson.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM.predict(\"The prime minister of the United Kingdom is \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain PromptTemplate\n",
    "\n",
    "LangChain prompts are templates in the following format, letting you bring your own variables retrieved from the structured and unstrutured documents we indexed into Elasticsearch\n",
    "\n",
    "The following code composes a prompt that could be used against OpenAI\n",
    "\n",
    "If you are using LLama2 or another LLM that requires special tokens to separate the system prompt, you'll need to add those yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI Chatbot that answers questions \n",
      "about past Presidential State of the Union addresses using only the following provided context.\n",
      "If you can't answer the question using the following context say \"I don't know\".\n",
      "\n",
      "Context: \n",
      "On March 1, 2022, President Biden said the following:\n",
      "shake the very foundations of the free world, thinking he could make it bend to his menacing ways. But he badly miscalculated. He thought he could roll into Ukraine and the world would roll over. Instead, he met with a wall of strength he never anticipated or imagined. He met the Ukrainian people.From President Zelenskiy, their—to every Ukrainian, their fearlessness, their courage, their determination literally inspires the world. Groups of citizens blocking tanks with their bodies.Everyone from students to retirees, to teachers turned soldiers defending their homeland. And in this struggle—President Zelenskiy said in his speech to the European Parliament, \"Light will win over darkness.\"The Ukrainian Ambassador to the United States is here tonight sitting with the First Lady. Let each of\n",
      "\n",
      "Human: what did Biden say about the Ukrainian people?\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE = \"\"\"You are a helpful AI Chatbot that answers questions \n",
    "about past Presidential State of the Union addresses using only the following provided context.\n",
    "If you can't answer the question using the following context say \"I don't know\".\n",
    "\n",
    "Context: \n",
    "On {date}, President {administration} said the following:\n",
    "{context}\n",
    "\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"date\", \"administration\", \"context\", \"input\"], \n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "print(PROMPT.format(\n",
    "    date= best_result.metadata[\"date\"],\n",
    "    administration= best_result.metadata[\"administration\"],\n",
    "    context= best_result.page_content,\n",
    "    input= human_input\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the LLM to work with the retrieved context\n",
    "\n",
    "remember ```best_result``` shoulds still have the retrieved document from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI Chatbot that answers questions \n",
      "about past Presidential State of the Union addresses using only the following provided context.\n",
      "If you can't answer the question using the following context say \"I don't know\".\n",
      "\n",
      "Context: \n",
      "On March 1, 2022, President Biden said the following:\n",
      "shake the very foundations of the free world, thinking he could make it bend to his menacing ways. But he badly miscalculated. He thought he could roll into Ukraine and the world would roll over. Instead, he met with a wall of strength he never anticipated or imagined. He met the Ukrainian people.From President Zelenskiy, their—to every Ukrainian, their fearlessness, their courage, their determination literally inspires the world. Groups of citizens blocking tanks with their bodies.Everyone from students to retirees, to teachers turned soldiers defending their homeland. And in this struggle—President Zelenskiy said in his speech to the European Parliament, \"Light will win over darkness.\"The Ukrainian Ambassador to the United States is here tonight sitting with the First Lady. Let each of\n",
      "\n",
      "Human: what did Biden say about the Ukrainian people?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "President Biden praised the Ukrainian people for their fearlessness, courage, and determination. He mentioned how they inspired the world with their actions, such as citizens blocking tanks with their bodies. President Zelenskiy also spoke about the Ukrainian people's determination and said, \"Light will win over darkness.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "conversation = LLMChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=LLM,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "ai_response = conversation.run(\n",
    "    date= best_result.metadata[\"date\"],\n",
    "    administration= best_result.metadata[\"administration\"],\n",
    "    context= best_result.page_content,\n",
    "    input= human_input\n",
    ")\n",
    "\n",
    "print(ai_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
